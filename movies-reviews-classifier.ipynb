{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFNPj5l9JIEOPp5ZngXCUD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thedatadj/natural-language-processing/blob/main/movies-reviews-classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description\n",
        "In this project I create a machine learning model capable of classifying movies reviews as positive or negative.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The dataset used for this project is the IMDB dataset consisting of movies reviews with labels indicating if the review is positive or negative."
      ],
      "metadata": {
        "id": "vxKkPhIT0Wwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maas, A. L., Daly, R. E., Pham, P. T., Huang, D., Ng, A. Y., & Potts, C. (2011). Learning Word Vectors for Sentiment Analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (pp. 142â€“150). Portland, Oregon, USA. Association for Computational Linguistics. [Link to the Paper](http://www.aclweb.org/anthology/P11-1015)\n"
      ],
      "metadata": {
        "id": "E-K7L8ty1bCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical analysis\n",
        "import numpy as np\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "\n",
        "# TensorFlow datasets\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "TagDEtO81ezA"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "bsSKvGv82jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "imdb_data = tfds.load('imdb_reviews',\n",
        "                      as_supervised=True)\n"
      ],
      "metadata": {
        "id": "17xDBSNJ2e9e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the training and testing datasets\n",
        "\n",
        "train_set = imdb_data['train']\n",
        "test_set = imdb_data['test']\n"
      ],
      "metadata": {
        "id": "pxBOZXeE2_OS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look into a training example\n",
        "\n",
        "next(iter(train_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJAfYynR5NGS",
        "outputId": "ab9f06cc-d266-4923-8819-ede1cbeae4e5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\">,\n",
              " <tf.Tensor: shape=(), dtype=int64, numpy=0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I want each training example to be a string, and store these in a list. I also want each label to be just an integer store in a list."
      ],
      "metadata": {
        "id": "au-ea1qw5g1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get training sentences and labels into a list**"
      ],
      "metadata": {
        "id": "jQ1NLaFd7xkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "for sentence, label in train_set:\n",
        "\n",
        "    # Sentence\n",
        "\n",
        "    # Extract string\n",
        "    string = sentence.numpy()\n",
        "    # Decode\n",
        "    decoded = string.decode('utf8')\n",
        "    # Add to list\n",
        "    training_sentences.append(decoded)\n",
        "\n",
        "    # Label\n",
        "\n",
        "    # Extract value\n",
        "    value = label.numpy()\n",
        "    # Add to list\n",
        "    training_labels.append(value)"
      ],
      "metadata": {
        "id": "ZX1EywLa4DYE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get testing sentences and labels into lists**"
      ],
      "metadata": {
        "id": "uQhegF2q8eKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lists\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "\n",
        "for sentence, label in test_set:\n",
        "    # Extract string\n",
        "    string = sentence.numpy()\n",
        "    # Decode\n",
        "    decoded = string.decode('utf8')\n",
        "    # Add to list\n",
        "    testing_sentences.append(decoded)\n",
        "\n",
        "    # Extract number\n",
        "    value = label.numpy()\n",
        "    # Add to list\n",
        "    testing_labels.append(value)"
      ],
      "metadata": {
        "id": "aGIrpbeh4utm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training example\n",
        "training_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "N20T7FCC48kW",
        "outputId": "e0cfff60-5206-4a32-86fa-3f5b72ca0060"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List to array\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "nn6eIH-j5DB9"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now the datasets are ready."
      ],
      "metadata": {
        "id": "Pgr_IHwP9ync"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "This step is necessary to fit the classifier later."
      ],
      "metadata": {
        "id": "3THDEZqv91tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparamters\n",
        "vocabulary_size = 10000\n",
        "embedding_dimension = 16\n",
        "maximum_lenght_of_sentences = 120\n",
        "truncating_type = 'post'\n",
        "out_of_vocabulary_token = \"<OOV>\""
      ],
      "metadata": {
        "id": "Ik90AWIf_Oqb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "sa1oChka9vt4"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate\n",
        "tokenizer = Tokenizer(num_words = vocabulary_size,\n",
        "                      oov_token = out_of_vocabulary_token)\n",
        "\n",
        "# Fit\n",
        "tokenizer.fit_on_texts(training_sentences)"
      ],
      "metadata": {
        "id": "NwfwE6aJ_HDk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the tokenizer is fit I can convert the sentences from my list of sentences `training_sentences` and `testing_sentences` into numbers using `tokenizer`"
      ],
      "metadata": {
        "id": "B9a8jXneADDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentences to sequences\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)"
      ],
      "metadata": {
        "id": "5PjyosZuAgAH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "print(\"Human:\", [word for word in training_sentences[0].split()][:6])\n",
        "print(\"Computer:\", sequences[0][:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1de00x0BAoG3",
        "outputId": "0b1207b2-c7a7-4e80-eaa6-f8b4f0198879"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: ['This', 'was', 'an', 'absolutely', 'terrible', 'movie.']\n",
            "Computer: [12, 14, 33, 425, 392, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I pad the sequences (sentences) into a matrix so that every training example have the same lenght."
      ],
      "metadata": {
        "id": "us97drP_BIWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences\n",
        "padded = pad_sequences(sequences,\n",
        "                       maxlen=maximum_lenght_of_sentences,\n",
        "                       truncating=truncating_type)"
      ],
      "metadata": {
        "id": "THSB0zzmAv77"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I apply the same process to the testing set."
      ],
      "metadata": {
        "id": "v-03M83zBpuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(testing_sequences,\n",
        "                               maxlen=maximum_lenght_of_sentences)"
      ],
      "metadata": {
        "id": "7_i5vpeEBn59"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "I define a neural network model."
      ],
      "metadata": {
        "id": "XYMAmkP5Dk_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocabulary_size,\n",
        "                              embedding_dimension,\n",
        "                              input_length=maximum_lenght_of_sentences),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(12, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "Y3NK5LoWCFli"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QcErt7xBEP6l"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameter\n",
        "n_epochs = 10"
      ],
      "metadata": {
        "id": "O2g6xJJ9FTwh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "model.fit(padded,\n",
        "          training_labels,\n",
        "          epochs=n_epochs,\n",
        "          validation_data=(testing_padded, testing_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imnn6iu2GJQX",
        "outputId": "50ad801b-73de-4d23-f287-996c29913fa4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.4822 - accuracy: 0.7504 - val_loss: 0.3436 - val_accuracy: 0.8471\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.2245 - accuracy: 0.9168 - val_loss: 0.3814 - val_accuracy: 0.8340\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.0711 - accuracy: 0.9828 - val_loss: 0.4893 - val_accuracy: 0.8219\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 9s 11ms/step - loss: 0.0151 - accuracy: 0.9984 - val_loss: 0.5805 - val_accuracy: 0.8226\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.6240 - val_accuracy: 0.8266\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 8s 11ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 0.8272\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 5.5887e-04 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8272\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 3.1043e-04 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8280\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 8s 10ms/step - loss: 1.8405e-04 - accuracy: 1.0000 - val_loss: 0.7914 - val_accuracy: 0.8286\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 10ms/step - loss: 1.1063e-04 - accuracy: 1.0000 - val_loss: 0.8250 - val_accuracy: 0.8282\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bae4e95a3b0>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Training accuracy is perfect. <br>\n",
        "Validation accuracy is not very close to training accuracy. <br>\n",
        "Therefore, this model migh be overfitting."
      ],
      "metadata": {
        "id": "DnF8tmwrIDGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results analysis"
      ],
      "metadata": {
        "id": "txIsMBqyLz42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(testing_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYFHG3caIagH",
        "outputId": "6e1fa251-3f22-454e-a378-b61acd659491"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.6054122e-02],\n",
              "       [9.9998307e-01],\n",
              "       [1.6896736e-09],\n",
              "       ...,\n",
              "       [4.0747193e-12],\n",
              "       [9.9911696e-01],\n",
              "       [9.9999672e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The first prediction is close to 0, this means that the model think that this review is negative, let's take a look."
      ],
      "metadata": {
        "id": "QQ5Xycd1J7hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "IXVAPCmTJwDU",
        "outputId": "76334fc1-75d0-44bf-debe-c0f524ce1a69"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"There are films that make careers. For George Romero, it was NIGHT OF THE LIVING DEAD; for Kevin Smith, CLERKS; for Robert Rodriguez, EL MARIACHI. Add to that list Onur Tukel's absolutely amazing DING-A-LING-LESS. Flawless film-making, and as assured and as professional as any of the aforementioned movies. I haven't laughed this hard since I saw THE FULL MONTY. (And, even then, I don't think I laughed quite this hard... So to speak.) Tukel's talent is considerable: DING-A-LING-LESS is so chock full of double entendres that one would have to sit down with a copy of this script and do a line-by-line examination of it to fully appreciate the, uh, breadth and width of it. Every shot is beautifully composed (a clear sign of a sure-handed director), and the performances all around are solid (there's none of the over-the-top scenery chewing one might've expected from a film like this). DING-A-LING-LESS is a film whose time has come.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> We can see that this review is fairly positive.\n",
        "\n",
        "Let's see the actual label for this review."
      ],
      "metadata": {
        "id": "a1GbufNpKgF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMr3tZ8LLVnH",
        "outputId": "93f6e0f5-c6fc-4ec2-9a63-7080c8b63cbe"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label is 1, which means that this review is positive, but the model predicted as being closer to negative."
      ],
      "metadata": {
        "id": "c7kUERqjLX9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, the last prediction is close to 1, which means that the algorithm thinks that this review is positive review."
      ],
      "metadata": {
        "id": "mxzhy9mXKqog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_sentences[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "JWMA5RoMJ1M0",
        "outputId": "e5afa35b-06ea-4e47-f371-53cb8c48bb3b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"They just don't make cartoons like they used to. This one had wit, great characters, and the greatest ensemble of voice over artists ever assembled for a daytime cartoon show. This still remains as one of the highest rated daytime cartoon shows, and one of the most honored, winning several Emmy Awards.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> And indeed it looks like a positive review."
      ],
      "metadata": {
        "id": "QHVi8CrxLjGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_labels[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6VIUulXLnCZ",
        "outputId": "cc5a1ac2-3d8a-45d5-efd1-812fb423ff3d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}