{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAvFoNo9gnNJZXWH2Rfpw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thedatadj/natural-language-processing/blob/main/text_generation_shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "8LqKbHYEMICx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY0nvwUGK2vK",
        "outputId": "a45b5b3a-5131-4969-d850-415d8a7ace6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "\r  0% 0.00/93.6k [00:00<?, ?B/s]\r100% 93.6k/93.6k [00:00<00:00, 68.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download file\n",
        "!gdown 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "with open(\"/content/sonnets.txt\") as file:\n",
        "    data = file.read()\n",
        "\n",
        "data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hVJzqTWgLaJ7",
        "outputId": "316129ac-ac3d-456a-a0fc-76ec73dcf924"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"FROM fairest creatures we desire increase,\\nThat thereby beauty's rose might never die,\\nBut as the ri\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "SDe26_-LMNd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "corpus = data.lower()\n",
        "corpus = corpus.split(\"\\n\")\n",
        "corpus[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVr24iZrLoUM",
        "outputId": "3613dec6-af7f-4fa6-dba7-a9fc1c4bc714"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from fairest creatures we desire increase,',\n",
              " \"that thereby beauty's rose might never die,\"]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "315lnXBtMVqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "DdzMq24gL44L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)"
      ],
      "metadata": {
        "id": "KB7zzgDeM8k2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index to word dictionary\n",
        "dic = tokenizer.word_index\n",
        "dic['the']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfM7F1irNOIK",
        "outputId": "7effa3d9-74d3-429f-9dce-bb7e144ec2f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constant number of unique words in the corpus\n",
        "TOTAL_WORDS = len(dic) + 1\n",
        "TOTAL_WORDS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt-lI7INNbTS",
        "outputId": "b830ce19-ce46-49db-9948-203a5fae96ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3211"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the tokenizer\n",
        "text = \"I love to sing\"\n",
        "tokenizer.texts_to_sequences([text])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDsXCfanNmYU",
        "outputId": "9136e689-7ba6-4db4-d1e4-0d8c1aa2f6cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 14, 3, 323]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## N-grams generator\n",
        "Maps a sequence to a sequence of n-grams."
      ],
      "metadata": {
        "id": "jU8Png0BOCSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_ngrams(sequence, tokenizer):\n",
        "    n_gram_sequences = []\n",
        "    token_list = tokenizer.texts_to_sequences([sequence])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        n_gram_sequences.append(n_gram_sequence)\n",
        "    return n_gram_sequences"
      ],
      "metadata": {
        "id": "QGTX7CdlNyHD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9PS2aZ9TPiJI",
        "outputId": "eaabd1f7-5620-4505-b8ee-0e2ade08b816"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I love to sing'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_ngrams(text, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3u9egfHPk99",
        "outputId": "ace0c874-82a7-4ef3-852b-9de1f961827e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 14], [6, 14, 3], [6, 14, 3, 323]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maps all sequences in the corpus to sequences of n-grams."
      ],
      "metadata": {
        "id": "kwK_QO2zPuRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        n_gram_sequences = seq_ngrams(line, tokenizer)\n",
        "        for sequence in n_gram_sequences:\n",
        "            input_sequences.append(sequence)\n",
        "    return input_sequences"
      ],
      "metadata": {
        "id": "ubiORexPPnL2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [text, \"I want to eat some bread\"]\n",
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhzre251QQIl",
        "outputId": "04550c3b-ed48-433c-ce70-59df0a679aa6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I love to sing', 'I want to eat some bread']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_seqs(texts, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IytsGdOQWpk",
        "outputId": "7b128b2d-bd91-4fc5-e2fe-c1fd86afd7be"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 14],\n",
              " [6, 14, 3],\n",
              " [6, 14, 3, 323],\n",
              " [6, 566],\n",
              " [6, 566, 3],\n",
              " [6, 566, 3, 637],\n",
              " [6, 566, 3, 637, 82]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform corpus\n",
        "Transform the corpus such that each line becomes a sequence of n-grams."
      ],
      "metadata": {
        "id": "SyEx2p09Spqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "input_sequences[:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW8osZESQeak",
        "outputId": "853deb77-2ea5-49e5-a16c-e0d9e7edf28f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517],\n",
              " [8, 878],\n",
              " [8, 878, 134]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the contants maximum sequence length"
      ],
      "metadata": {
        "id": "L3qBLQClTC_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of each sequence of n-grams\n",
        "len_ngrams = [len(sequence) for sequence in input_sequences]\n",
        "MAX_SEQUENCE_LEN = max(len_ngrams)\n",
        "MAX_SEQUENCE_LEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j1Ra3brS7rW",
        "outputId": "f1caa578-dc20-4c2e-e197-8cf342565c20"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padd sequences"
      ],
      "metadata": {
        "id": "EcO2nm50Tk7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import padder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "BTkffQIMTaMR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences = pad_sequences(input_sequences, maxlen=MAX_SEQUENCE_LEN, padding='pre')"
      ],
      "metadata": {
        "id": "pbN9AM9EUIsT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTEEArVyUZ65",
        "outputId": "c2e2ac11-a75a-4680-b68b-198f3b96a5a8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwHRS4crUb65",
        "outputId": "7264a2a5-38ae-434d-8455-b804f815eeeb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  34, 417, 877, 166],\n",
              "       [  0,   0,   0,   0,   0,   0,  34, 417, 877, 166, 213],\n",
              "       [  0,   0,   0,   0,   0,  34, 417, 877, 166, 213, 517]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HacREncbUeDJ",
        "outputId": "8dd4a226-c135-4cc8-eccf-ef2b22f88d42"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15462, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data split"
      ],
      "metadata": {
        "id": "xYAVQxq2U4uJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = padded_sequences[:, :-1]\n",
        "labels = padded_sequences[:, -1]"
      ],
      "metadata": {
        "id": "TMMhf59yU2-Q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQrgINr4VejX",
        "outputId": "c752dc54-5995-45c8-d208-22ebb697f629"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,  34],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,   0,   0,   0,   0,  34, 417, 877, 166],\n",
              "       [  0,   0,   0,   0,   0,  34, 417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "923oj1QNVfuf",
        "outputId": "9d25121d-8d0a-4529-c537-6d899c002a3b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([417, 877, 166, 213, 517], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaOFpbXeWelF",
        "outputId": "0899e994-cb5e-4e00-e4e4-c05f55e595ec"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15462, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make labels into one hot categorical vector."
      ],
      "metadata": {
        "id": "K9Bvp62FVi6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "35MydPZKVhjH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = to_categorical(labels, num_classes=TOTAL_WORDS)\n",
        "labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6xWzVlWVt8c",
        "outputId": "d0977ec1-c100-4fb2-cb05-1424fd9c18a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IosYMH69V11l",
        "outputId": "38f70380-2c90-413c-b609-f1f34b36242f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15462, 3211)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "92iJJI_QWAYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense"
      ],
      "metadata": {
        "id": "XuLvd_9zV4vG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(TOTAL_WORDS, 100, input_length=MAX_SEQUENCE_LEN-1),\n",
        "    Bidirectional(LSTM(150)),\n",
        "    Dense(TOTAL_WORDS, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UtIq9-uUWM9p"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "history = model.fit(features, labels, epochs=50, verbose=0)"
      ],
      "metadata": {
        "id": "7DIIOfulW5XD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "vbUMmiDgXVKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training accuracy\n",
        "history.history['accuracy'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjS9EWudXNSr",
        "outputId": "7f0cd10b-07f5-424e-a76a-213bed17015f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8487905859947205"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demostration"
      ],
      "metadata": {
        "id": "Sn7jiOV_YtB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "jqi_i33XZS_u"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = \"I love to eat bread with nutella\"\n",
        "next_words = 50\n",
        "\n",
        "for i in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed])[0]\n",
        "    token_list_padded = pad_sequences([token_list], maxlen=MAX_SEQUENCE_LEN-1, padding='pre')\n",
        "    predicted = model.predict(token_list_padded, verbose=0)\n",
        "    predicted = np.argmax(predicted, axis=-1).item()\n",
        "    output_word = tokenizer.index_word[predicted]\n",
        "    seed += \" \" + output_word\n",
        "\n",
        "seed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "vrutNJzRYuQu",
        "outputId": "ec1e2128-16d9-44a1-d21c-3f8afb15cec6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I love to eat bread with nutella your sweet image add be die to more more worth worth me well transferr'd so dearer free done mine own best worth be the done sweet treasure cheeks treasure cheeks so long right back of nought ' behavior tongue worth old time dost lie to me are you so dearer\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            Based on\n",
        "        </td>\n",
        "        <td>\n",
        "            Assignment from the TensorFlow Specialization\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "1wGM5K4eZiit"
      }
    }
  ]
}