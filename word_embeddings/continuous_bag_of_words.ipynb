{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wl51Qc3XxE-IARI-Sbcpl84MX23BoGas",
      "authorship_tag": "ABX9TyNhLiZuxSfWuj1+ffncY+jG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thedatadj/natural-language-processing/blob/main/word_embeddings/continuous_bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create word embeddings using the continuous bags of words model."
      ],
      "metadata": {
        "id": "M9oOfkDn-hpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the data"
      ],
      "metadata": {
        "id": "fhsgrzAkDEA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "vvtwmgOQDQvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUESj0Av-Mxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b21c624b-419d-454c-9c93-82b6119c8c53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O for a Muse of fire, that would ascend\\nThe bright'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "with open(\"/content/shakespeare.txt\") as file:\n",
        "    data = file.read()\n",
        "data[:50]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is a continuos string."
      ],
      "metadata": {
        "id": "NwRQ7b1SDeXO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace punctuations by a `.`"
      ],
      "metadata": {
        "id": "x14fgDleDny1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool\n",
        "import re\n",
        "\n",
        "# Replace\n",
        "punctuations = r\"[,!?:-]\"\n",
        "data = re.sub(punctuations, '.', data)\n",
        "data[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "l3TXQesvDc2A",
        "outputId": "49e3ae62-7def-404a-a0ab-08976b7ed21f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'O for a Muse of fire. that would ascend\\nThe bright'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize the data"
      ],
      "metadata": {
        "id": "WDBw-9AIEGOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.data.path.append('.')\n",
        "\n",
        "# Tokenize\n",
        "data = word_tokenize(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJOmIywcEBti",
        "outputId": "405b8b72-7efc-438c-81a9-43656485b0e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yscGJj9EqUN",
        "outputId": "86c3784f-fb5d-43d0-824d-27ebe350774d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`data` is now a list of tokens."
      ],
      "metadata": {
        "id": "sY3MLXv-EuYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xuQsEwyEjcu",
        "outputId": "27ec7def-8a6f-4e3f-96aa-5d254d7d213c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'for', 'a', 'Muse', 'of', 'fire', '.', 'that', 'would', 'ascend']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lower case all words."
      ],
      "metadata": {
        "id": "TMtNyK96E22i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [token.lower() for token in data]\n",
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnzYyV2EtXb",
        "outputId": "a804f762-4481-4d80-9065-48e7403a940c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o', 'for', 'a', 'muse', 'of', 'fire', '.', 'that', 'would', 'ascend']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop non-alphabetical tokens."
      ],
      "metadata": {
        "id": "zo6xn9n8FAxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [token for token in data if token.isalpha() or token == '.']\n",
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGQU-pMfE_GL",
        "outputId": "7962816c-ede6-45c7-a8c8-c4665511013b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['o', 'for', 'a', 'muse', 'of', 'fire', '.', 'that', 'would', 'ascend']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX7d2uDkFPzp",
        "outputId": "7f01f9a2-1868-4199-d995-ed33df6f229f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60432"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a total of 60,432 tokens in this dataset."
      ],
      "metadata": {
        "id": "ZC-7BjMjFWuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get a frequency dictionary, that also acts as a vocabulary of unique words in the dataset."
      ],
      "metadata": {
        "id": "_ERrI2XUFfFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq = {}\n",
        "for token in data:\n",
        "    if token not in freq:\n",
        "        freq[token] = 0\n",
        "    freq[token] += 1\n",
        "print(\"Frequency of 'the' is\", freq['the'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFa9vgfAFVhJ",
        "outputId": "e539e423-ee62-4fb1-d83c-b2e264550df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency of 'the' is 1521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get two dictionary\n",
        "* `word2Ind`: maps tokens to indices.\n",
        "* `Ind2word`: maps indices to tokens."
      ],
      "metadata": {
        "id": "DnDE1qF5GJUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2Ind = {}\n",
        "Ind2word = {}\n",
        "tokens = sorted(list(set(data)))\n",
        "for idx, token in enumerate(tokens):\n",
        "    word2Ind[token] = idx\n",
        "    Ind2word[idx] = token"
      ],
      "metadata": {
        "id": "KVFS6h4CF4pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2Ind['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYeegBzAHANo",
        "outputId": "5ba6aca3-d375-42c5-ef1e-262aefd64fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2744"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ind2word[2743]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ffb7MwY7HcM2",
        "outputId": "60c83fb9-092d-4d93-d6e4-cbb7971962ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kinds'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store the size of the vocabulary of tokens in a variable."
      ],
      "metadata": {
        "id": "JVYwOMt6Hi7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V = len(freq)\n",
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TLKWfsNHfj2",
        "outputId": "935de849-8883-4221-9a7e-72512910505c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5775"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "bOhbwgdoHs5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization\n"
      ],
      "metadata": {
        "id": "kdlvEDF9H2K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool\n",
        "import numpy as np\n",
        "\n",
        "def initialize_model(N, V, random_seed=1):\n",
        "    '''\n",
        "        Returns: W1, W2, b1, b2\n",
        "    '''\n",
        "    np.random.seed(1)\n",
        "    W1 = np.random.rand(N, V)\n",
        "    W2 = np.random.rand(V, N)\n",
        "    b1 = np.random.rand(N, 1)\n",
        "    b2 = np.random.rand(V, 1)\n",
        "    return W1, W2, b1, b2"
      ],
      "metadata": {
        "id": "XGbu594aHpf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax activation function"
      ],
      "metadata": {
        "id": "Jpe5V88aJVfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    numerator = np.exp(z)\n",
        "    denominator = np.sum(numerator, axis=0)\n",
        "    return numerator / denominator"
      ],
      "metadata": {
        "id": "-w8eVYyqJXiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward propagation"
      ],
      "metadata": {
        "id": "MfMseOBvKJwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(x, W1, W2, b1, b2):\n",
        "    '''\n",
        "        Returns: z, h\n",
        "    '''\n",
        "    h = W1.dot(x) + b1\n",
        "    h = np.maximum(0, h)\n",
        "    z = W2.dot(h) + b2\n",
        "    return z, h"
      ],
      "metadata": {
        "id": "RX0y7ao4KLjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cost function"
      ],
      "metadata": {
        "id": "NCyYSnMgLUvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(y, yhat, batch_size):\n",
        "    logyhat = np.log(yhat)\n",
        "    loss = np.multiply(logyhat, y)\n",
        "    cost = -1 / batch_size * np.sum(loss)\n",
        "    cost = np.squeeze(cost)\n",
        "    return cost"
      ],
      "metadata": {
        "id": "8JJe4boxLWeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation"
      ],
      "metadata": {
        "id": "tx9FbPisMCmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size):\n",
        "    z1 = W1.dot(x) + b1\n",
        "    l1 = W2.T.dot(yhat - y)\n",
        "    l1[z1 < 0] = 0\n",
        "    grad_W1 = 1 / batch_size * l1.dot(x.T)\n",
        "    grad_W2 = 1 / batch_size * (yhat - y).dot(h.T)\n",
        "    grad_b1 = 1 / batch_size * np.sum(l1, axis=1, keepdims=True)\n",
        "    grad_b2 = 1 / batch_size * np.sum(yhat - y, axis=1, keepdims=True)\n",
        "    return grad_W1, grad_W2, grad_b1, grad_b2"
      ],
      "metadata": {
        "id": "vUPPdkhQL9Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient descent"
      ],
      "metadata": {
        "id": "Dvgu4XdOWA1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function that yields batches of the training data."
      ],
      "metadata": {
        "id": "ANNZcrUfWGmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "abq8bETqWY_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idx(words, word2Ind):\n",
        "    idx = []\n",
        "    for word in words:\n",
        "        idx = idx + [word2Ind[word]]\n",
        "    return idx"
      ],
      "metadata": {
        "id": "coXHu90gWW-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pack_idx_with_frequency(context_words, word2Ind):\n",
        "    freq_dict = defaultdict(int)\n",
        "    for word in context_words:\n",
        "        freq_dict[word] += 1\n",
        "    idxs = get_idx(context_words, word2Ind)\n",
        "    packed = []\n",
        "    for i in range(len(idxs)):\n",
        "        idx = idxs[i]\n",
        "        freq = freq_dict[context_words[i]]\n",
        "        packed.append((idx, freq))\n",
        "    return packed"
      ],
      "metadata": {
        "id": "KVxI5p2_WUsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vectors(data, word2Ind, V, C):\n",
        "    i = C\n",
        "    while True:\n",
        "        y = np.zeros(V)\n",
        "        x = np.zeros(V)\n",
        "        center_word = data[i]\n",
        "        y[word2Ind[center_word]] = 1\n",
        "        context_words = data[(i - C) : i] + data[(i + 1) : (i + C + 1)]\n",
        "        num_ctx_words = len(context_words)\n",
        "        for idx, freq in pack_idx_with_frequency(context_words, word2Ind):\n",
        "            x[idx] = freq / num_ctx_words\n",
        "        yield x, y\n",
        "        i += 1\n",
        "        if i >= len(data) - C:\n",
        "            print(\"i is being set to\", C)\n",
        "            i = C"
      ],
      "metadata": {
        "id": "foG5762HWSrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(data, word2Ind, V, C, batch_size):\n",
        "    batch_x = []\n",
        "    batch_y = []\n",
        "    for x, y in get_vectors(data, word2Ind, V, C):\n",
        "        if len(batch_x) < batch_size:\n",
        "            batch_x.append(x)\n",
        "            batch_y.append(y)\n",
        "        else:\n",
        "            yield np.array(batch_x).T, np.array(batch_y).T\n",
        "            batch_x = []\n",
        "            batch_y = []"
      ],
      "metadata": {
        "id": "TVtSz6b8WB_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(data, word2Ind, N, V, num_iters, alpha=0.03,\n",
        "                     random_seed=282, initialize_model=initialize_model,\n",
        "                     get_batches=get_batches, forward_prop=forward_prop,\n",
        "                     softmax=softmax, compute_cost=compute_cost,\n",
        "                     back_prop=back_prop):\n",
        "    W1, W2, b1, b2 = initialize_model(N, V, random_seed=random_seed)\n",
        "    batch_size = 128\n",
        "    iters = 0\n",
        "    C = 2\n",
        "    for x, y in get_batches(data, word2Ind, V, C, batch_size):\n",
        "        z, h = forward_prop(x, W1, W2, b1, b2)\n",
        "        yhat = softmax(z)\n",
        "        cost = compute_cost(y, yhat, batch_size)\n",
        "        if ( (iters+1) % 10 == 0):\n",
        "            print(f\"iters: {iters + 1} cost: {cost:.6f}\")\n",
        "        grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y,\n",
        "                                                       h, W1, W2, b1,\n",
        "                                                       b2, batch_size)\n",
        "        W1 = W1 - alpha * grad_W1\n",
        "        W2 = W2 - alpha * grad_W2\n",
        "        b1 = b1 - alpha * grad_b1\n",
        "        b2 = b2 - alpha * grad_b2"
      ],
      "metadata": {
        "id": "BRsadDZXWclD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            Based on\n",
        "        </td>\n",
        "        <td>\n",
        "            Assignment from the Natural Language Processing Specialization in Coursera.\n",
        "        </td>\n",
        "    </tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "9tp8StuPZd6k"
      }
    }
  ]
}